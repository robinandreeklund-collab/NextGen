  - sprint: 4.4
    name: Meta-bel√∂ningsjustering via RewardTunerAgent
    goal: Introducera RewardTunerAgent som meta-agent mellan portfolio_manager och rl_controller f√∂r att justera och optimera bel√∂ningssignaler baserat p√• marknadsf√∂rh√•llanden och performance.
    modules:
      - reward_tuner (NY)
      - rl_controller
      - portfolio_manager
      - strategic_memory_engine
      - introspection_panel
    adaptive_parameters:
      reward_tuner:
        - reward_scaling_factor (0.5-2.0, default: 1.0)
        - volatility_penalty_weight (0.0-1.0, default: 0.3)
        - overfitting_detector_threshold (0.05-0.5, default: 0.2)
    reward_signals:
      - base_reward: Raw reward fr√•n portfolio_manager
      - tuned_reward: Justerad reward efter RewardTunerAgent
      - reward_stability: Stabilitet i bel√∂ningssignaler
      - overfitting_risk: Risk f√∂r √∂veranpassning
    feedback_flow:
      - portfolio_manager ‚Üí reward_tuner (base_reward)
      - reward_tuner ‚Üí rl_controller (tuned_reward)
      - rl_controller ‚Üí reward_tuner (agent_performance feedback)
      - strategic_memory_engine ‚Üê reward_tuner (reward_log)
    testable:
      - RewardTunerAgent justerar bel√∂ning baserat p√• volatilitet
      - Overfitting detection fungerar korrekt
      - Reward scaling p√•verkar RL-agenttr√§ning
      - Reward flow loggas i strategic_memory_engine
      - Visualisering i introspection_panel
    status: üîÑ p√•g√•ende
