# ğŸš€ NextGen AI Trader

Ett sjÃ¤lvreflekterande, modulÃ¤rt och RL-drivet handelssystem byggt fÃ¶r transparens, agentutveckling och realtidsanalys. Systemet simulerar handel med verkliga data, strategier, feedbackloopar och belÃ¶ningsbaserad inlÃ¤rning.

## ğŸ¯ Snabbstart

### KÃ¶r Analyzer Debug Dashboard
```bash
python analyzer_debug.py
# Ã–ppna http://localhost:8050 i webblÃ¤saren
```

### KÃ¶r Simulering
```bash
python sim_test.py
```

### KÃ¶r Tester
```bash
pytest tests/ -v
```

---

## ğŸ“ Sprintstatus

| Sprint | Status | Beskrivning |
|--------|--------|-------------|
| Sprint 1 | âœ… FÃ¤rdig | KÃ¤rnsystem och demoportfÃ¶lj |
| Sprint 2 | âœ… FÃ¤rdig | RL och belÃ¶ningsflÃ¶de |
| Sprint 3 | âœ… FÃ¤rdig | Feedbackloopar och introspektion |
| Sprint 4 | âœ… FÃ¤rdig | Strategiskt minne och agentutveckling |
| Sprint 4.2 | âœ… FÃ¤rdig | Adaptiv parameterstyrning via RL/PPO |
| Sprint 4.3 | âœ… FÃ¤rdig | Full adaptiv parameterstyrning i alla moduler |
| Sprint 4.4 | âœ… FÃ¤rdig | Meta-belÃ¶ningsjustering via RewardTunerAgent |
| Sprint 5 | âœ… FÃ¤rdig | Simulering och konsensus |
| Sprint 6 | âœ… FÃ¤rdig | Tidsanalys och action chains |
| Sprint 7 | âœ… FÃ¤rdig | Indikatorvisualisering och systemÃ¶versikt |

**Testresultat:** âœ… 214/214 tester passerar (100%)

---

## ğŸ” Analyzer Debug Dashboard

**analyzer_debug.py** - Omfattande debug- och analysdashboard fÃ¶r hela NextGen systemet.

### Funktioner

Dashboard med 6 huvudsektioner:

1. **System Overview**
   - SystemhÃ¤lsa (health score 0-100%)
   - Modulstatus (aktiva/stale moduler)
   - RealtidsÃ¶vervakning av alla komponenter

2. **Data Flow & Simulation**
   - Prisutveckling fÃ¶r alla symboler
   - Tekniska indikatorer (RSI, MACD, ATR)
   - BeslutsflÃ¶de (decisions, executions, success rate)

3. **RL Analysis**
   - Reward flow (base vs tuned rewards, Sprint 4.4)
   - Parameter evolution (adaptiva parametrar, Sprint 4.3)
   - Agent performance (training loss per agent)

4. **Agent Development**
   - Agent evolution (versioner Ã¶ver tid)
   - Agent metriker (performance per agent)
   - Evolutionshistorik

5. **Debug & Logging**
   - Event log (realtidslogg av alla events)
   - Feedback flow (visualisering av feedback)
   - Timeline analysis (Sprint 6)

6. **Portfolio**
   - Portfolio vÃ¤rde (cash, holdings, total)
   - Positioner (nuvarande innehav)
   - P&L och ROI

### AnvÃ¤ndning

```bash
# Starta dashboarden
python analyzer_debug.py

# Ã–ppna webblÃ¤saren pÃ¥
http://localhost:8050
```

**Kontroller:**
- Start Simulation: Startar simulerad trading
- Stop Simulation: Stoppar simulering
- Auto-refresh: Uppdaterar var 2:a sekund

**DatakÃ¤llor:**
- Ã…teranvÃ¤nder kod frÃ¥n sim_test.py fÃ¶r datainmatning
- Integrerar med alla moduler via message_bus
- Realtidsdata frÃ¥n introspection_panel, system_monitor, RL-controller

---

## ğŸ“¦ SystemÃ¶versikt

### KÃ¤rnmoduler

| Modul | Beskrivning | Sprint |
|-------|-------------|--------|
| `analyzer_debug.py` | Debug dashboard med fullstÃ¤ndig systemvisualisering | Sprint 7 |
| `data_ingestion.py` | WebSocket-dataflÃ¶de frÃ¥n Finnhub | Sprint 1 |
| `strategy_engine.py` | Genererar tradefÃ¶rslag baserat pÃ¥ indikatorer | Sprint 1-2 |
| `risk_manager.py` | RiskbedÃ¶mning och justering | Sprint 1-2 |
| `decision_engine.py` | Fattar handelsbeslut | Sprint 1-2 |
| `execution_engine.py` | Exekverar trades | Sprint 1 |
| `portfolio_manager.py` | Hanterar portfÃ¶lj och genererar rewards | Sprint 1, 4.4 |
| `rl_controller.py` | PPO-agenttrÃ¤ning och distribution | Sprint 2, 4.2 |
| `reward_tuner.py` | Meta-belÃ¶ningsjustering | Sprint 4.4 |
| `vote_engine.py` | AgentrÃ¶stning | Sprint 4.3, 5 |
| `consensus_engine.py` | Konsensusbeslut | Sprint 5 |
| `decision_simulator.py` | Beslutssimuleringar | Sprint 5 |
| `timespan_tracker.py` | Timeline-analys | Sprint 6 |
| `action_chain_engine.py` | Ã…teranvÃ¤ndbara beslutskedjor | Sprint 6 |
| `system_monitor.py` | SystemhÃ¤lsoÃ¶vervakning | Sprint 6 |
| `strategic_memory_engine.py` | Beslutshistorik och analys | Sprint 4 |
| `meta_agent_evolution_engine.py` | Agentevolution | Sprint 4 |
| `agent_manager.py` | Agentprofiler och versioner | Sprint 4 |
| `feedback_router.py` | Intelligent feedback-routing | Sprint 3 |
| `feedback_analyzer.py` | MÃ¶nsteranalys i feedback | Sprint 3 |
| `introspection_panel.py` | Dashboard-data fÃ¶r visualisering | Sprint 3, 7 |

### Adaptiva Parametrar

Systemet har **16 adaptiva parametrar** som justeras automatiskt via RL/PPO:

**Sprint 4.4 (RewardTunerAgent):**
- reward_scaling_factor (0.5-2.0)
- volatility_penalty_weight (0.0-1.0)
- overfitting_detector_threshold (0.05-0.5)

**Sprint 4.2 (Meta-parametrar):**
- evolution_threshold (0.05-0.5)
- min_samples (5-50)
- update_frequency (1-100)
- agent_entropy_threshold (0.1-0.9)

**Sprint 4.3 (Modulparametrar):**
- signal_threshold (0.1-0.9) - Strategy Engine
- indicator_weighting (0.0-1.0) - Strategy Engine
- risk_tolerance (0.01-0.5) - Risk Manager
- max_drawdown (0.01-0.3) - Risk Manager
- consensus_threshold (0.5-1.0) - Decision Engine
- memory_weighting (0.0-1.0) - Decision Engine
- agent_vote_weight (0.1-2.0) - Vote Engine
- execution_delay (0-10) - Execution Engine
- slippage_tolerance (0.001-0.05) - Execution Engine

---

## ğŸ—ï¸ Systemarkitektur

### DataflÃ¶de

```
Market Data (Finnhub) â†’ Data Ingestion â†’ Indicators
                                              â†“
                                    Strategy Engine â† RL Controller
                                              â†“
                                      Risk Manager
                                              â†“
                                    Decision Engine â† Memory/Voting
                                              â†“
                                    Execution Engine
                                              â†“
                                   Portfolio Manager â†’ Base Reward
                                              â†“
                                      Reward Tuner â†’ Tuned Reward
                                              â†“
                                       RL Controller â†’ Agent Updates
```

### Reward Flow (Sprint 4.4)

RewardTunerAgent transformerar volatila portfolio rewards till stabila RL-signaler:

1. **Portfolio Manager** â†’ base_reward (rÃ¥data)
2. **Reward Tuner** â†’ analys och transformation
   - BerÃ¤kna volatilitet
   - Detektera overfitting
   - Applicera penalties
   - Skala med reward_scaling_factor
3. **RL Controller** â†’ tuned_reward (stabil signal)

**Transformation Ratio:** 0.67 genomsnitt (33% reduktion vid hÃ¶g volatilitet)

## ğŸš€ Kom igÃ¥ng

### Installation

```bash
# Klona repositoryt
git clone https://github.com/robinandreeklund-collab/NextGen.git
cd NextGen

# Installera dependencies
pip install -r requirements.txt

# KÃ¶r tester
pytest tests/ -v
```

### Snabbstart

```bash
# 1. Starta debug-dashboarden (rekommenderat)
python analyzer_debug.py
# â†’ Ã–ppna http://localhost:8050

# 2. KÃ¶r simulering i terminal
python sim_test.py

# 3. KÃ¶r med live WebSocket-data (krÃ¤ver Finnhub API-nyckel)
python websocket_test.py
```

---

## ğŸ¨ Funktioner

### ğŸ” Analyzer Debug Dashboard
- Realtidsvisualisering av hela systemet
- 6 sektioner: System, Data Flow, RL Analysis, Agent Development, Debug, Portfolio
- Start/stop kontroller fÃ¶r simulering
- Auto-refresh var 2:a sekund

### ğŸ¤– Adaptiv RL-optimering
- **16 adaptiva parametrar** som justeras automatiskt via PPO
- Reward transformation fÃ¶r stabil trÃ¤ning (Sprint 4.4)
- Meta-parameterstyrning (Sprint 4.2, 4.3)
- Agent evolution och versionshantering (Sprint 4)

### ğŸ—³ï¸ Konsensusbeslutsfattande
- Simulering av alternativa beslut (Sprint 5)
- RÃ¶stmatris med viktning (Sprint 5)
- 4 konsensusmodeller: Majority, Weighted, Unanimous, Threshold

### â° Timeline och Action Chains
- Tidsbaserad spÃ¥rning av beslut (Sprint 6)
- Ã…teranvÃ¤ndbara beslutskedjor (Sprint 6)
- SystemhÃ¤lsoÃ¶vervakning (Sprint 6)

### ğŸ“Š Omfattande indikatorstÃ¶d
- Tekniska: RSI, MACD, ATR, Bollinger Bands, ADX, Stochastic
- Fundamentala: EPS, ROE, ROA, Analyst Ratings, Earnings
- Alternativa: News Sentiment, Insider Sentiment, ESG Score

---

## ğŸ“ Projektstruktur

```
NextGen/
â”œâ”€â”€ analyzer_debug.py           # ğŸ†• Debug dashboard
â”œâ”€â”€ sim_test.py                 # Simulerad trading
â”œâ”€â”€ websocket_test.py           # Live trading med Finnhub
â”œâ”€â”€ modules/                    # Alla kÃ¤rnmoduler (26 stycken)
â”‚   â”œâ”€â”€ reward_tuner.py         # Sprint 4.4: Reward transformation
â”‚   â”œâ”€â”€ rl_controller.py        # Sprint 2, 4.2: PPO-agenter
â”‚   â”œâ”€â”€ consensus_engine.py     # Sprint 5: Konsensusbeslut
â”‚   â”œâ”€â”€ timespan_tracker.py     # Sprint 6: Timeline-analys
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dashboards/                 # Dash-visualiseringar
â”œâ”€â”€ tests/                      # 214 tester (100% pass rate)
â”œâ”€â”€ docs/                       # Dokumentation och YAML-specs
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Testning

```bash
# KÃ¶r alla tester
pytest tests/ -v

# KÃ¶r specifika test-suiter
pytest tests/test_reward_tuner.py -v              # Sprint 4.4
pytest tests/test_adaptive_parameters_sprint4_3.py -v  # Sprint 4.3
pytest tests/test_consensus_engine.py -v          # Sprint 5
pytest tests/test_timespan_tracker.py -v          # Sprint 6

# Med coverage
pytest tests/ --cov=modules --cov-report=html
```

**Testresultat:** âœ… 214/214 tester passerar

---

## ğŸ“ˆ Prestanda och Metriker

### Reward Transformation (Sprint 4.4)
- Base rewards: 50
- Tuned rewards: 50 (1:1 match)
- Volatilitet: 31.31 genomsnitt, 48.75 senaste
- Transformation ratio: 0.67 (33% reduktion vid hÃ¶g volatilitet)
- **Resultat:** Stabilare RL-trÃ¤ning, bÃ¤ttre generalisering

### Konsensus (Sprint 5)
- 1000 beslut processade
- Robusthet: 0.88 genomsnitt
- Konsensus confidence: 0.19 (konservativ trading)
- **Resultat:** Risk-medvetet beslutsfattande

### System Health
- Module health score: 0.95+ (95%+)
- 214/214 tester passerar
- Alla 26 moduler aktiva

---

## ğŸ”— Integrationer och API

### Finnhub API
- WebSocket fÃ¶r realtidsdata
- REST API fÃ¶r indikatorer
- KrÃ¤ver API-nyckel (gratis tier tillrÃ¤cklig)

### Message Bus
- Central pub/sub-kommunikation
- 20+ topics fÃ¶r modul-kommunikation
- Event logging fÃ¶r debugging

---

## ğŸ“š Detaljerad Dokumentation

FÃ¶r detaljerad information om sprintar, implementationer och arkitektur:

- **Sprint-dokumentation:** Se `README_detailed_backup.md`
- **YAML-specifikationer:** Se `docs/` fÃ¶r alla system-specs
- **Test-dokumentation:** Se `docs/reward_tuner_sprint4_4/rl_test_suite.yaml`

---

## ğŸ¤ Sprint-sammanfattning

| Sprint | Fokus | Nyckelfunktioner |
|--------|-------|------------------|
| **1** | KÃ¤rnsystem | WebSocket, Strategy, Execution, Portfolio |
| **2** | RL | PPO-agenter, Reward flow, Agent training |
| **3** | Feedback | Feedback routing, Analyzer, Introspection |
| **4** | Memory & Evolution | Strategic memory, Agent evolution, Versions |
| **4.2** | Adaptiv RL | Meta-parametrar (4 stycken) |
| **4.3** | Modulparametrar | 9 adaptiva modulparametrar |
| **4.4** | Reward Tuner | Reward transformation, Volatility control |
| **5** | Konsensus | Decision simulator, Voting, 4 consensus models |
| **6** | Timeline | Timeline tracking, Action chains, System monitor |
| **7** | Visualisering | **analyzer_debug.py**, Resource planner, Teams |

---

## ğŸ› ï¸ Utveckling

### Kodstil
- Python 3.8+
- Type hints fÃ¶r alla funktioner
- Docstrings fÃ¶r alla moduler och klasser
- PEP 8-kompatibel

### CI/CD
- Automatiska tester vid varje push
- 100% test pass rate krÃ¤vs
- Coverage tracking

---

## ğŸ“ Licens och Credits

NextGen AI Trader Ã¤r utvecklat som ett demonstrations- och utbildningssystem fÃ¶r:
- Reinforcement Learning i trading
- ModulÃ¤r systemarkitektur
- Agent-baserat beslutsfattande
- Adaptiv parameterstyrning

**OBS:** Detta Ã¤r ett simulerings- och utbildningssystem. AnvÃ¤nd inte fÃ¶r verklig trading utan grundlig testning och riskbedÃ¶mning.
